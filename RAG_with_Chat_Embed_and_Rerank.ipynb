{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61bac5b5",
   "metadata": {
    "id": "61bac5b5"
   },
   "source": [
    "# RAG with Chat, Embed, and Rerank\n",
    "\n",
    "This notebook shows how to build a RAG-powered chatbot with Cohere's Chat endpoint.  The chatbot can extract relevant information from external documents and produce verifiable, inline citations in its responses.\n",
    "\n",
    "This application will use several Cohere API endpoints:\n",
    "\n",
    "- Chat: For handling the main logic of the chatbot, including turning a user message into queries, generating responses, and producing citations\n",
    "- Embed: For turning textual documents into their embeddings representation, later to be used in retrieval (we’ll use the latest, state-of-the-art Embed v3 model)\n",
    "- Rerank: For reranking the retrieved documents according to their relevance to a query\n",
    "\n",
    "The diagram below provides an overview of what we’ll build.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ab2d5d",
   "metadata": {
    "id": "f6ab2d5d"
   },
   "source": [
    "Here is a summary of the steps involved.\n",
    "\n",
    "Initial phase:\n",
    "- **Step 0**: Ingest the documents – get documents, chunk, embed, and index.\n",
    "\n",
    "For each user-chatbot interaction:\n",
    "- **Step 1**: Get the user message\n",
    "- **Step 2**: Call the Chat endpoint in query-generation mode\n",
    "- If at least one query is generated\n",
    "  - **Step 3**: Retrieve and rerank relevant documents\n",
    "  - **Step 4**: Call the Chat endpoint in document mode to generate a grounded response with citations\n",
    "- If no query is generated\n",
    "  - **Step 4**: Call the Chat endpoint in normal mode to generate a response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TWyo_5WoNUM-",
   "metadata": {
    "id": "TWyo_5WoNUM-"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5pLAhQmTOKiV",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T14:15:00.070260Z",
     "start_time": "2024-07-21T14:14:57.855171Z"
    },
    "id": "5pLAhQmTOKiV"
   },
   "outputs": [],
   "source": [
    "! pip install cohere hnswlib unstructured -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3a03a57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T12:24:10.646813Z",
     "start_time": "2024-07-24T12:24:06.438824Z"
    },
    "id": "f3a03a57"
   },
   "outputs": [],
   "source": [
    "import cohere\n",
    "import uuid\n",
    "import hnswlib #vector library\n",
    "from typing import List, Dict\n",
    "from unstructured.partition.html import partition_html\n",
    "from unstructured.chunking.title import chunk_by_title\n",
    "\n",
    "co = cohere.Client(\"F8OTjXKgp4KZrk3UBga3jwrmg3opliFg7XqGvXhf\") # Get your API key here: https://dashboard.cohere.com/api-keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Dx1cncziCWBB",
   "metadata": {
    "cellView": "form",
    "id": "Dx1cncziCWBB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d34e4b7",
   "metadata": {},
   "source": [
    "# Create a vector store for ingestion and retrieval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588ed6d0",
   "metadata": {},
   "source": [
    "![RAG components - Vectorstore](../images/llmu/rag/rag-components-vectorstore.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7e7d1c",
   "metadata": {
    "id": "2f7e7d1c"
   },
   "source": [
    "\n",
    "First, we define the list of documents we want to ingest and make available for retrieval. As an example, we'll use the contents from the first module of Cohere's *LLM University: What are Large Language Models?*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dca4a88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T14:15:03.868478Z",
     "start_time": "2024-07-21T14:15:03.865831Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "3dca4a88",
    "outputId": "b05da1ee-0456-4387-c232-a43e0ffed54c"
   },
   "outputs": [],
   "source": [
    "# raw_documents = [\n",
    "#     {\n",
    "#          \"title\": \"Text Embeddings\",\n",
    "#         \"url\": \"https://docs.cohere.com/docs/text-embeddings\"},\n",
    "#     {\n",
    "#         \"title\": \"Similarity Between Words and Sentences\",\n",
    "#         \"url\": \"https://docs.cohere.com/docs/similarity-between-words-and-sentences\"},\n",
    "#     {\n",
    "#         \"title\": \"The Attention Mechanism\",\n",
    "#         \"url\": \"https://docs.cohere.com/docs/the-attention-mechanism\"},\n",
    "#     {\n",
    "#         \"title\": \"Transformer Models\",\n",
    "#         \"url\": \"https://docs.cohere.com/docs/transformer-models\"}\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d17b0d2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T12:24:13.979581Z",
     "start_time": "2024-07-24T12:24:13.971140Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_documents = [\n",
    "    {\n",
    "        \"title\": \"Verdes by Haven\",\n",
    "        \"url\": \"https://www.aldar.com/VerdesbyHaven/\"},\n",
    "    {\n",
    "        \"title\": \"Aldar Sustainability Strategy\",\n",
    "        \"url\": \"https://www.aldar.com/en/explore-aldar/sustainability/strategy\"},\n",
    "    {\n",
    "        \"title\": \"The Properties\",\n",
    "        \"url\": \"https://www.aldar.com/properties/en\"},\n",
    "    {\n",
    "        \"title\": \"Company Strategy\",\n",
    "        \"url\": \"https://www.aldar.com/en/explore-aldar/about-aldar/strategy\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2a8968",
   "metadata": {
    "id": "5e2a8968"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c33412c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T12:24:16.701442Z",
     "start_time": "2024-07-24T12:24:16.673662Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "7c33412c",
    "outputId": "cf04f8ed-8000-4433-f976-2d37747f21e7"
   },
   "outputs": [],
   "source": [
    "class Vectorstore:\n",
    "    \"\"\"\n",
    "    A class representing a collection of documents indexed into a vectorstore.\n",
    "\n",
    "    Parameters:\n",
    "    raw_documents (list): A list of dictionaries representing the sources of the raw documents. Each dictionary should have 'title' and 'url' keys.\n",
    "\n",
    "    Attributes:\n",
    "    raw_documents (list): A list of dictionaries representing the raw documents.\n",
    "    docs (list): A list of dictionaries representing the chunked documents, with 'title', 'text', and 'url' keys.\n",
    "    docs_embs (list): A list of the associated embeddings for the document chunks.\n",
    "    docs_len (int): The number of document chunks in the collection.\n",
    "    idx (hnswlib.Index): The index used for document retrieval.\n",
    "\n",
    "    Methods:\n",
    "    load_and_chunk(): Loads the data from the sources and partitions the HTML content into chunks.\n",
    "    embed(): Embeds the document chunks using the Cohere API.\n",
    "    index(): Indexes the document chunks for efficient retrieval.\n",
    "    retrieve(): Retrieves document chunks based on the given query.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, raw_documents: List[Dict[str, str]]):\n",
    "        self.raw_documents = raw_documents\n",
    "        self.docs = []\n",
    "        self.docs_embs = []\n",
    "        self.retrieve_top_k = 10\n",
    "        self.rerank_top_k = 3\n",
    "        self.load_and_chunk()\n",
    "        self.embed()\n",
    "        self.index()\n",
    "\n",
    "\n",
    "    def load_and_chunk(self) -> None:\n",
    "        \"\"\"\n",
    "        Loads the text from the sources and chunks the HTML content.\n",
    "        \"\"\"\n",
    "        print(\"Loading documents...\")\n",
    "\n",
    "        for raw_document in self.raw_documents:\n",
    "            elements = partition_html(url=raw_document[\"url\"])\n",
    "            chunks = chunk_by_title(elements)\n",
    "            for chunk in chunks:\n",
    "                self.docs.append(\n",
    "                    {\n",
    "                        \"title\": raw_document[\"title\"],\n",
    "                        \"text\": str(chunk),\n",
    "                        \"url\": raw_document[\"url\"],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    def embed(self) -> None:\n",
    "        \"\"\"\n",
    "        Embeds the document chunks using the Cohere API.\n",
    "        \"\"\"\n",
    "        print(\"Embedding document chunks...\")\n",
    "\n",
    "        batch_size = 90\n",
    "        self.docs_len = len(self.docs)\n",
    "        for i in range(0, self.docs_len, batch_size):\n",
    "            batch = self.docs[i : min(i + batch_size, self.docs_len)]\n",
    "            texts = [item[\"text\"] for item in batch]\n",
    "            docs_embs_batch = co.embed(\n",
    "                texts=texts, model=\"embed-english-v3.0\", input_type=\"search_document\"\n",
    "            ).embeddings\n",
    "            self.docs_embs.extend(docs_embs_batch)\n",
    "\n",
    "    def index(self) -> None:\n",
    "        \"\"\"\n",
    "        Indexes the document chunks for efficient retrieval.\n",
    "        \"\"\"\n",
    "        print(\"Indexing document chunks...\")\n",
    "\n",
    "        self.idx = hnswlib.Index(space=\"ip\", dim=1024)\n",
    "        self.idx.init_index(max_elements=self.docs_len, ef_construction=512, M=64)\n",
    "        self.idx.add_items(self.docs_embs, list(range(len(self.docs_embs))))\n",
    "\n",
    "        print(f\"Indexing complete with {self.idx.get_current_count()} document chunks.\")\n",
    "\n",
    "    def retrieve(self, query: str) -> List[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Retrieves document chunks based on the given query.\n",
    "\n",
    "        Parameters:\n",
    "        query (str): The query to retrieve document chunks for.\n",
    "\n",
    "        Returns:\n",
    "        List[Dict[str, str]]: A list of dictionaries representing the retrieved document chunks, with 'title', 'text', and 'url' keys.\n",
    "        \"\"\"\n",
    "\n",
    "        # Dense retrieval\n",
    "        query_emb = co.embed(\n",
    "            texts=[query], model=\"embed-english-v3.0\", input_type=\"search_query\"\n",
    "        ).embeddings\n",
    "\n",
    "        doc_ids = self.idx.knn_query(query_emb, k=self.retrieve_top_k)[0][0]\n",
    "\n",
    "        # Reranking\n",
    "        rank_fields = [\"title\", \"text\"] # We'll use the title and text fields for reranking\n",
    "\n",
    "        docs_to_rerank = [self.docs[doc_id] for doc_id in doc_ids]\n",
    "\n",
    "        rerank_results = co.rerank(\n",
    "            query=query,\n",
    "            documents=docs_to_rerank,\n",
    "            top_n=self.rerank_top_k,\n",
    "            model=\"rerank-english-v3.0\",\n",
    "           # rank_fields=rank_fields\n",
    "        )\n",
    "\n",
    "        doc_ids_reranked = [doc_ids[result.index] for result in rerank_results.results]\n",
    "\n",
    "        docs_retrieved = []\n",
    "        for doc_id in doc_ids_reranked:\n",
    "            docs_retrieved.append(\n",
    "                {\n",
    "                    \"title\": self.docs[doc_id][\"title\"],\n",
    "                    \"text\": self.docs[doc_id][\"text\"],\n",
    "                    \"url\": self.docs[doc_id][\"url\"],\n",
    "                }\n",
    "            )\n",
    "\n",
    "        return docs_retrieved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bf5d85",
   "metadata": {
    "id": "e1bf5d85"
   },
   "source": [
    "In the code cell below, we initialize an instance of the `Vectorstore` class and pass in the `raw_documents` list as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4643e630",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T12:24:28.978513Z",
     "start_time": "2024-07-24T12:24:21.735825Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "4643e630",
    "outputId": "fe01fcb6-3574-4322-d8d0-57d37aad397d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents...\n",
      "Embedding document chunks...\n",
      "Indexing document chunks...\n",
      "Indexing complete with 48 document chunks.\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the Vectorstore class with the given sources\n",
    "vectorstore = Vectorstore(raw_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61928287",
   "metadata": {
    "id": "61928287"
   },
   "source": [
    "The `Vectorstore` class also has a `retrieve()` method, which we'll use to retrieve relevant document chunks given a query .  This method has two components: (1) dense retrieval, and (2) reranking.\n",
    "\n",
    "### Dense retrieval\n",
    "\n",
    "First, we embed the query using the same `embed-english-v3.0` model we used to embed the document chunks, but this time we set `input_type=\"search_query\"`.\n",
    "\n",
    "Search is performed by the `knn_query()` method from the `hnswlib` library. Given a query, it returns the document chunks most similar to the query. We can define the number of document chunks to return using the attribute `self.retrieve_top_k=10`.\n",
    "\n",
    "### Reranking\n",
    "\n",
    "After semantic search, we implement a reranking step.  While our semantic search component is already highly capable of retrieving relevant sources, the [Rerank endpoint](https://cohere.com/rerank) provides an additional boost to the quality of the search results, especially for complex and domain-specific queries. It takes the search results and sorts them according to their relevance to the query.\n",
    "\n",
    "We call the Rerank endpoint with the `co.rerank()` method and define the number of top reranked document chunks to retrieve using the attribute `self.rerank_top_k=3`.  The model we use is `rerank-english-v2.0`.  \n",
    "\n",
    "This method returns the top retrieved document chunks `chunks_retrieved` so that they can be passed to the chatbot.\n",
    "\n",
    "In the code cell below, we check the document chunks that are retrieved for the query `\"multi-head attention definition\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OwozNf_uPEyX",
   "metadata": {
    "id": "OwozNf_uPEyX"
   },
   "source": [
    "## Test Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82617b91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T17:17:32.686421Z",
     "start_time": "2024-07-22T17:17:31.981253Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "id": "82617b91",
    "outputId": "7f1f2bc8-8ed9-4190-bd6b-7af2d9dc1980"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Company Strategy',\n",
       "  'text': \"Our Company's\\n\\nStrategy\\n\\nOur Purpose\\n\\nWe build eco-systems around an intimate understanding of our stakeholders.\\n\\nOur work is well-designed for communities to thrive and raise their families, for corporate cultures to innovate & prosper and for schools where young talent meets great teaching.\\n\\nWe are human centric with a collection of talented people, businesses and suppliers coming together in a powerful eco-system built on strong relationships.\",\n",
       "  'url': 'https://www.aldar.com/en/explore-aldar/about-aldar/strategy'},\n",
       " {'title': 'Company Strategy',\n",
       "  'text': 'Shaping the journey towards growth\\n\\nOur strategy shapes our journey towards future growth, enriching customer experiences and maximising shareholder value as we pursue our goals and realise our vision.\\n\\nOperational Excellence\\n\\nCustomer Centricity\\n\\nGrowth and Expansion\\n\\nPeople, Innovation and Digital Transformation\\n\\nOperational Excellence\\n\\nOur agile processes ensure we deliver our developments on time, within budget, and to the highest standards of excellence.',\n",
       "  'url': 'https://www.aldar.com/en/explore-aldar/about-aldar/strategy'},\n",
       " {'title': 'Company Strategy',\n",
       "  'text': 'Strategy\\n\\nSponsorships\\n\\nProcurement\\n\\nAldar Square\\n\\nE-Services\\n\\nAll E-Services\\n\\nCustomer Portal\\n\\nKhidmah\\n\\nProvis\\n\\nAldar Brokers\\n\\nAldar IOS App\\n\\nAldar Android App\\n\\nBusinesses - Development\\n\\nAll Businesses - Development\\n\\nResidential\\n\\nLand Portfolio\\n\\nBusinesses - Investment\\n\\nAll Businesses - Investment\\n\\nCommercial\\n\\nRetail\\n\\nEducation\\n\\nAll Education\\n\\nHospitality\\n\\nAll Hospitality\\n\\nProjects\\n\\nAll Projects\\n\\nCorporate Governance\\n\\nAll Corporate Governance\\n\\nSustainability\\n\\nAll Sustainability',\n",
       "  'url': 'https://www.aldar.com/en/explore-aldar/about-aldar/strategy'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore.retrieve(\"what is company strategy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae81baa",
   "metadata": {},
   "source": [
    "# Create a chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69fbca9",
   "metadata": {
    "id": "e69fbca9"
   },
   "source": [
    "\n",
    "Next, we implement a class to handle the interaction between the user and the chatbot.  It takes an instance of the `Vectorstore` class as input.\n",
    "\n",
    "The `run()` method will be used to run the chatbot application.  It begins with the logic for getting the user message, along with a way for the user to end the conversation.  \n",
    "\n",
    "Based on the user message, the chatbot needs to decide if it needs to consult external information before responding.  If so, the chatbot determines an optimal set of search queries to use for retrieval.  When we call `co.chat()` with `search_queries_only=True`, the Chat endpoint handles this for us automatically.\n",
    "\n",
    "The generated queries can be accessed from the `search_queries` field of the object that is returned.  Then, what happens next depends on how many queries are returned.\n",
    "- If queries are returned, we call the `retrieve()` method of the Vectorstore object for the  retrieval step.  The retrieved document chunks are then passed to the Chat endpoint by adding a `documents` parameter when we call `co.chat()` again.\n",
    "- Otherwise, if no queries are returned, we call the Chat endpoint another time, passing the user message and without needing to add any documents to the call.\n",
    "\n",
    "In either case, we also pass the `conversation_id` parameter, which retains the interactions between the user and the chatbot in the same conversation thread. We also enable the `stream` parameter so we can stream the chatbot response.\n",
    "\n",
    "We then print the chatbot's response.  In the case that the external information was used to generate a response, we also display citations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2c15a1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T17:17:51.825365Z",
     "start_time": "2024-07-22T17:17:51.815947Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "d2c15a1f",
    "outputId": "8daa9159-338c-45ec-e9ed-830aedcdf0d8"
   },
   "outputs": [],
   "source": [
    "class Chatbot:\n",
    "    def __init__(self, vectorstore: Vectorstore):\n",
    "        \"\"\"\n",
    "        Initializes an instance of the Chatbot class.\n",
    "\n",
    "        Parameters:\n",
    "        vectorstore (Vectorstore): An instance of the Vectorstore class.\n",
    "\n",
    "        \"\"\"\n",
    "        self.vectorstore = vectorstore\n",
    "        self.conversation_id = str(uuid.uuid4())\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Runs the chatbot application.\n",
    "\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            print(f\"\\n{'-'*100}\\n\")\n",
    "            # Get the user message\n",
    "            message = input(\"User: \")\n",
    "\n",
    "            # Typing \"quit\" ends the conversation\n",
    "            if message.lower() == \"quit\":\n",
    "              print(\"Ending chat.\")\n",
    "              break\n",
    "           \n",
    "\n",
    "            # Generate search queries (if any)\n",
    "            response = co.chat(message=message,\n",
    "                               model=\"command-r\",\n",
    "                               search_queries_only=True)\n",
    "\n",
    "            # If there are search queries, retrieve document chunks and respond\n",
    "            if response.search_queries:\n",
    "                print(\"Retrieving information...\", end=\"\")\n",
    "\n",
    "                # Retrieve document chunks for each query\n",
    "                documents = []\n",
    "                for query in response.search_queries:\n",
    "                    documents.extend(self.vectorstore.retrieve(query.text))\n",
    "\n",
    "                # Use document chunks to respond\n",
    "                response = co.chat_stream(\n",
    "                    message=message,\n",
    "                    model=\"command-r-plus\",\n",
    "                    documents=documents,\n",
    "                    conversation_id=self.conversation_id,\n",
    "                )\n",
    "\n",
    "            # If there is no search query, directly respond\n",
    "            else:\n",
    "                response = co.chat_stream(\n",
    "                    message=message,\n",
    "                    model=\"command-r-plus\",\n",
    "                    conversation_id=self.conversation_id,\n",
    "                )\n",
    "\n",
    "            # Print the chatbot response, citations, and documents\n",
    "            print(\"\\nChatbot:\")\n",
    "            citations = []\n",
    "            cited_documents = []\n",
    "\n",
    "            # Display response\n",
    "            for event in response:\n",
    "                if event.event_type == \"text-generation\":\n",
    "                    print(event.text, end=\"\")\n",
    "                elif event.event_type == \"citation-generation\":\n",
    "                    citations.extend(event.citations)\n",
    "                elif event.event_type == \"stream-end\":\n",
    "                    cited_documents = event.response.documents\n",
    "\n",
    "            # Display citations and source documents\n",
    "            if citations:\n",
    "              print(\"\\n\\nCITATIONS:\")\n",
    "              for citation in citations:\n",
    "                print(citation)\n",
    "\n",
    "              print(\"\\nDOCUMENTS:\")\n",
    "              for document in cited_documents:\n",
    "                print(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "F0X9FZqwOwQ6",
   "metadata": {
    "id": "F0X9FZqwOwQ6"
   },
   "source": [
    "# Run the chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb442f7",
   "metadata": {
    "id": "3cb442f7"
   },
   "source": [
    "We can now run the chatbot.  For this, we create the instance of `Chatbot` and run the chatbot by invoking the `run()` method.\n",
    "\n",
    "The format of each citation is:\n",
    "- `start`: The starting point of a span where one or more documents are referenced\n",
    "- `end`: The ending point of a span where one or more documents are referenced\n",
    "- `text`: The text representing this span\n",
    "- `document_ids`: The IDs of the documents being referenced (`doc_0` being the ID of the first document passed to the `documents` creating parameter in the endpoint call, and so on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42d3f345",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T17:19:59.421446Z",
     "start_time": "2024-07-22T17:17:58.665933Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "42d3f345",
    "outputId": "8b935c8b-b1d4-4913-bdf8-73ba503402b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "User: what is the company strategy\n",
      "Retrieving information...\n",
      "Chatbot:\n",
      "Aldar's company strategy is to shape the journey towards growth, enriching customer experiences and maximising shareholder value. The company's strategic objectives are:\n",
      "- Future-proofing fiscal strength\n",
      "- Driving maximum financial returns for shareholders by continually growing its portfolio and exploring new opportunities\n",
      "- Operational excellence\n",
      "- Customer centricity\n",
      "- Growth and expansion\n",
      "- People, innovation and digital transformation\n",
      "\n",
      "Aldar's purpose is to build ecosystems around an intimate understanding of its stakeholders. The company's work is designed for communities to thrive, corporate cultures to innovate and prosper, and for schools to foster young talent. Aldar is human-centric, bringing together talented people, businesses, and suppliers in a powerful ecosystem built on strong relationships.\n",
      "\n",
      "CITATIONS:\n",
      "start=31 end=63 text='shape the journey towards growth' document_ids=['doc_1']\n",
      "start=65 end=95 text='enriching customer experiences' document_ids=['doc_1']\n",
      "start=100 end=129 text='maximising shareholder value.' document_ids=['doc_1', 'doc_2']\n",
      "start=172 end=203 text='Future-proofing fiscal strength' document_ids=['doc_2']\n",
      "start=206 end=325 text='Driving maximum financial returns for shareholders by continually growing its portfolio and exploring new opportunities' document_ids=['doc_2']\n",
      "start=328 end=350 text='Operational excellence' document_ids=['doc_1']\n",
      "start=353 end=372 text='Customer centricity' document_ids=['doc_1']\n",
      "start=375 end=395 text='Growth and expansion' document_ids=['doc_1']\n",
      "start=398 end=443 text='People, innovation and digital transformation' document_ids=['doc_1', 'doc_2']\n",
      "start=467 end=537 text='build ecosystems around an intimate understanding of its stakeholders.' document_ids=['doc_0']\n",
      "start=573 end=679 text='communities to thrive, corporate cultures to innovate and prosper, and for schools to foster young talent.' document_ids=['doc_0']\n",
      "start=689 end=702 text='human-centric' document_ids=['doc_0']\n",
      "start=722 end=819 text='talented people, businesses, and suppliers in a powerful ecosystem built on strong relationships.' document_ids=['doc_0']\n",
      "\n",
      "DOCUMENTS:\n",
      "{'id': 'doc_1', 'text': 'Shaping the journey towards growth\\n\\nOur strategy shapes our journey towards future growth, enriching customer experiences and maximising shareholder value as we pursue our goals and realise our vision.\\n\\nOperational Excellence\\n\\nCustomer Centricity\\n\\nGrowth and Expansion\\n\\nPeople, Innovation and Digital Transformation\\n\\nOperational Excellence\\n\\nOur agile processes ensure we deliver our developments on time, within budget, and to the highest standards of excellence.', 'title': 'Company Strategy', 'url': 'https://www.aldar.com/en/explore-aldar/about-aldar/strategy'}\n",
      "{'id': 'doc_2', 'text': 'People, innovation and digital transformation\\n\\nWe seek to attract and retain high performing talent, nurture an innovative and creative culture and adopt disruptive technology to help us achieve our vision.\\n\\nOur Strategic Objectives\\n\\nFuture-proofing our fiscal strength\\n\\nThe Financial Horizon\\n\\nOur goal is to drive maximum financial returns for our shareholders by continually growing our portfolio and exploring new opportunities.\\n\\nRead more\\n\\nClose\\n\\n01\\n\\nMaximise shareholder value.\\n\\n02', 'title': 'Company Strategy', 'url': 'https://www.aldar.com/en/explore-aldar/about-aldar/strategy'}\n",
      "{'id': 'doc_0', 'text': \"Our Company's\\n\\nStrategy\\n\\nOur Purpose\\n\\nWe build eco-systems around an intimate understanding of our stakeholders.\\n\\nOur work is well-designed for communities to thrive and raise their families, for corporate cultures to innovate & prosper and for schools where young talent meets great teaching.\\n\\nWe are human centric with a collection of talented people, businesses and suppliers coming together in a powerful eco-system built on strong relationships.\", 'title': 'Company Strategy', 'url': 'https://www.aldar.com/en/explore-aldar/about-aldar/strategy'}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "User: Brief about the project Verdes by Haven\n",
      "Retrieving information...\n",
      "Chatbot:\n",
      "Verdes by Haven is Aldar's final phase of apartment living in Dubai's first wellness-inspired community. The project is centred around sustainability and human-centric community design, with carefully considered measures to reduce utility bills and contribute to a greener, earth-friendly living experience. These measures include energy and water efficiency, natural lighting, shaded walkways and bikeways, and easy accessibility to services and public transport. The community also features generous green spaces, native landscaping, and EV charging facilities.\n",
      "\n",
      "CITATIONS:\n",
      "start=27 end=38 text='final phase' document_ids=['doc_1']\n",
      "start=42 end=58 text='apartment living' document_ids=['doc_1']\n",
      "start=62 end=104 text=\"Dubai's first wellness-inspired community.\" document_ids=['doc_1']\n",
      "start=135 end=149 text='sustainability' document_ids=['doc_0']\n",
      "start=154 end=184 text='human-centric community design' document_ids=['doc_0']\n",
      "start=191 end=220 text='carefully considered measures' document_ids=['doc_0']\n",
      "start=224 end=244 text='reduce utility bills' document_ids=['doc_0']\n",
      "start=249 end=307 text='contribute to a greener, earth-friendly living experience.' document_ids=['doc_0']\n",
      "start=331 end=358 text='energy and water efficiency' document_ids=['doc_0']\n",
      "start=360 end=376 text='natural lighting' document_ids=['doc_0']\n",
      "start=378 end=406 text='shaded walkways and bikeways' document_ids=['doc_0']\n",
      "start=412 end=464 text='easy accessibility to services and public transport.' document_ids=['doc_0']\n",
      "start=493 end=514 text='generous green spaces' document_ids=['doc_0']\n",
      "start=516 end=534 text='native landscaping' document_ids=['doc_0']\n",
      "start=540 end=563 text='EV charging facilities.' document_ids=['doc_0']\n",
      "\n",
      "DOCUMENTS:\n",
      "{'id': 'doc_1', 'text': 'Go to Aldar.com\\n\\nRegister your interest\\n\\nIntroducing\\n\\nApartment living in Dubai’s first wellness-inspired community\\n\\nAfter the record-breaking sales of Haven, Aldar proudly presents the final chance to own a home in Haven’s final phase—only 25 minutes from Downtown Dubai.\\n\\nDiscover Wellness Living\\n\\nWellness living is now within reach. Make your home in a place where every moment has been curated to enhance your wellbeing.\\n\\nExplore Verdes by Haven', 'title': 'Verdes by Haven', 'url': 'https://www.aldar.com/VerdesbyHaven/'}\n",
      "{'id': 'doc_0', 'text': 'Sustainable  homes\\n\\nVerdes by Haven looks after the wellbeing of the environment too. Carefully considered sustainability measures will help to reduce your utility bills, and contribute towards a greener, earth-friendly living experience.\\n\\nHuman-centric community design\\n\\nEnergy and water efficiency\\n\\nOptimised HVAC system\\n\\nNatural lighting\\n\\nGenerous green spaces\\n\\nNative landscaping\\n\\nEasy accessibility to services\\n\\nPublic transport\\n\\nShaded walkways & bikeways\\n\\nEV charging facilities', 'title': 'Verdes by Haven', 'url': 'https://www.aldar.com/VerdesbyHaven/'}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "User: can you provide the property details in abu dhabi\n",
      "Retrieving information...\n",
      "Chatbot:\n",
      "I was unable to find any specific property details for Abu Dhabi. However, Aldar's website does provide an overview of the Abu Dhabi market, as well as information on the Darna Loyalty Program.\n",
      "\n",
      "CITATIONS:\n",
      "start=107 end=139 text='overview of the Abu Dhabi market' document_ids=['doc_0', 'doc_1']\n",
      "start=171 end=193 text='Darna Loyalty Program.' document_ids=['doc_0', 'doc_1']\n",
      "\n",
      "DOCUMENTS:\n",
      "{'id': 'doc_0', 'text': '360 View\\n\\nBuy\\n\\nResidential\\n\\nBuilding Plots\\n\\nRent\\n\\nResidential\\n\\nCommercial\\n\\nRetail\\n\\nFAQs\\n\\nAbu Dhabi\\n\\nDarna Loyalty Program\\n\\nContact Us\\n\\nWHISTLEBLOWER SYSTEM\\n\\nExplore Abu Dhabi\\n\\nMarket Overview\\n\\nGolden Visa\\n\\nDari\\n\\nMedia\\n\\nNews\\n\\nGallery\\n\\nBlog\\n\\nInvestors Relations\\r\\n   \\r\\n   06\\n\\nReports & Presentations\\n\\nShareholder Center\\n\\nDebt Investors\\n\\nAnalyst Coverage\\n\\nFinancial Calendar\\n\\nCompany Announcements\\n\\nContact Us\\n\\nCareers\\n\\nExplore Aldar\\n\\nAbout Aldar\\n\\nAll About Aldar\\n\\nStory\\n\\nLeadership\\n\\nCulture and Values', 'title': 'Company Strategy', 'url': 'https://www.aldar.com/en/explore-aldar/about-aldar/strategy'}\n",
      "{'id': 'doc_1', 'text': 'We use cookies to offer you a better user experience. By continuing to use this website, you consent to the use of cookies in accordance with our  Privacy policy\\n\\nNo, I want more info\\n\\nCommunities\\n\\nProperties\\n\\nContact\\n\\nFAQS\\n\\nABU DHABI\\n\\nDARNA LOYALTY PROGRAM\\n\\nCONTACT US\\n\\nWHISTLEBLOWER SYSTEM\\n\\nEXPLORE ABU DHABI\\n\\nMarket Overview\\n\\nGolden Visa\\n\\nDari\\n\\nMEDIA\\n\\nNews\\n\\nGallery\\n\\nBlog\\n\\nINVESTORS RELATIONS\\n\\nReports & Presentations\\n\\nShareholder Center\\n\\nDebt Investors\\n\\nAnalyst Coverage\\n\\nFinancial Calendar', 'title': 'The Properties', 'url': 'https://www.aldar.com/properties/en'}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What are the properties project Aldar has\n",
      "Retrieving information...\n",
      "Chatbot:\n",
      "Sorry, I was unable to find any information about Aldar's properties projects.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m chatbot \u001b[38;5;241m=\u001b[39m Chatbot(vectorstore)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Run the chatbot\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mchatbot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 21\u001b[0m, in \u001b[0;36mChatbot.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Get the user message\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUser: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Typing \"quit\" ends the conversation\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquit\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py:1175\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_stdin:\n\u001b[1;32m   1172\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[1;32m   1173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1174\u001b[0m     )\n\u001b[0;32m-> 1175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py:1217\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1216\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# Create an instance of the Chatbot class\n",
    "chatbot = Chatbot(vectorstore)\n",
    "\n",
    "# Run the chatbot\n",
    "chatbot.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e69aa7c",
   "metadata": {
    "id": "9e69aa7c"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
